Для тестирования схожести предложений используется bert-base-uncased и sentence transformer, которые были обучены на датасете 'glue' - "stsb". (Полученный в результате обучения файл - Model(Similarity)_1703909050553345.pth)
Для генерации похожих предложений применяется 3 варианта, либо только unmasking - bert-base-uncased, либо только генерация текста - gpt2, либо и unmasking и генерация текста. (В таком случае происходит сначала unmsking, а потом для всех его результатов сначала обрезается некая часть, после чего генерируется новая)
Количество предложений выбрать нельзя, но можно выбрать минимальную схожесть предложений с оригинальным (мне это показалось более важным, а реализовывать сразу два параметра - вызывает сложности с тем, что либо процесс будет очень долгим, так как будут генерироваться одинаковые предложения, либо процесс никогда не закончится если лимит по количеству слишком высок)
Кроме минимальной схожести можно также выбрать количество слов, которые подвергаются маскингу (при этом все происходит последовательно, то есть маскировка 1 слова даст нам 5 вариантов на выходе, 2-ух и более - по 5 вариантов для каждого сгенерированного предложения на предыдущем этапе (2 = 25 вариантов, 3 = 125 вариантов и т.д.))
При выбора с генерацией, варианты предложения будут генерироваться либо на основе исходного предложения, либо на основе всех предложений, которые были сгенерированы на этапе маскинга
В результатах генерации возможно наличие почти полностью идентичных предложений (все полностью одинаковые - убираются, но предложения отличающиеся только знаком на конце - сохраняются).
Примеры результатов с различными параметрами и входными предложениями представлены в файлах Result_xxx.json